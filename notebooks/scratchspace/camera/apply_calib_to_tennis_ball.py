
"""
This file takes an image of a tennis ball and applies the camera calibration matrix to reproject the tennis ball's
coordinates in 3D space. The steps are as follows:
1. Set IMAGE_PATH to the correct path of the tennis ball image.
2. Set CALIB_MATRIX to the path of the camera calibration matrix.
3. Define the color ranges for the tennis ball in the HSV color space. (You don't have to do this)

Then, the file:
- uses our OpenCV code (generated by Claude AI with background subtraction, etc.) to detect the tennis ball
- finds the pixel coordinates of the image of the tennis ball
- recenters the image coordinates so that the x-coordinates are centered at the image center (because our robot will be at the center of the image)
- reprojects the centered image coordinates to 3D space using the camera calibration matrix
- visualizes the original image, the 2D image points, and the reprojected 3D points

"""



import cv2
import numpy as np
from matplotlib import pyplot as plt
from IPython import display

# CONSTANTS
IMAGE_PATH = 'tennis_ball/image_22.jpg'
CALIB_MATRIX = 'camera_calibration-2_3.npz'
Y_FLIP = True
X_FLIP = True

# Define multiple color ranges for different lighting conditions
color_ranges = [
    (np.array([20, 40, 80]), np.array([80, 255, 255])),  # Yellow-green
    (np.array([15, 30, 70]), np.array([85, 255, 255]))   # Broader range
]

# Start capturing video from the USB camera
frame = cv2.imread(IMAGE_PATH)

# Create background subtractor
bg_subtractor = cv2.createBackgroundSubtractorMOG2(detectShadows=True)


# Apply a slight Gaussian blur to reduce noise
blurred_frame = cv2.GaussianBlur(frame, (5, 5), 0)

# Convert the frame to the HSV color space
hsv = cv2.cvtColor(blurred_frame, cv2.COLOR_BGR2HSV)

# Create a mask for the tennis ball color (combine multiple ranges)
mask = np.zeros(hsv.shape[:2], dtype=np.uint8)
for lower, upper in color_ranges:
    mask |= cv2.inRange(hsv, lower, upper)

# Apply background subtraction
fg_mask = bg_subtractor.apply(frame)

# Combine color mask with foreground mask
combined_mask = cv2.bitwise_and(mask, fg_mask)

# Perform morphological operations to remove noise and improve detection
kernel = np.ones((5, 5), np.uint8)
combined_mask = cv2.morphologyEx(combined_mask, cv2.MORPH_OPEN, kernel)
combined_mask = cv2.morphologyEx(combined_mask, cv2.MORPH_CLOSE, kernel)

# Find contours
contours, _ = cv2.findContours(combined_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

# Tennis Ball Centers
tennis_ball_centers = []

# Track the tennis balls
x, y = None, None
for contour in contours:
    area = cv2.contourArea(contour)
    if area > 100:  # Adjust this threshold as needed
        perimeter = cv2.arcLength(contour, True)
        circularity = 4 * np.pi * (area / (perimeter ** 2))
        if circularity > 0.7:  # Enforce circularity check
            (x, y), radius = cv2.minEnclosingCircle(contour)
            center = (int(x), int(y))
            tennis_ball_centers.append(center)
            radius = int(radius)
            # Draw the circle and centroid on the frame
            cv2.circle(frame, center, radius, (0, 255, 0), 2)
            cv2.circle(frame, center, 5, (0, 128, 255), -1)

# Edit image coordinates such that the x coords are at the center of the image
frame_x_center = frame.shape[1] // 2
tennis_ball_centers = [(x - frame_x_center, y) for x, y in tennis_ball_centers]

# Display the resulting frame
frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
display.clear_output(wait=True)
plt.imshow(frame_rgb)
plt.show()

print("Tennis ball pixel coords: ", tennis_ball_centers)

# Load the calibration data
with np.load(CALIB_MATRIX) as calibration_data:
    mtx = calibration_data['camera_matrix']  # Camera matrix
    dist = calibration_data['dist_coeffs']  # Distortion coefficients
    rvecs = calibration_data['rvecs']  # Rotation vectors
    tvecs = calibration_data['tvecs']  # Translation vectors


import numpy as np
import cv2
import matplotlib.pyplot as plt

import numpy as np
import cv2
import matplotlib.pyplot as plt


def center_image_coordinates(image_points, frame_shape):
    """
    Center the image coordinates so that the vertical center line is at x=0

    :param image_points: Nx2 array of 2D image points
    :param frame_shape: Shape of the image frame (height, width)
    :return: Nx2 array of centered 2D image points
    """
    image_center_x = frame_shape[1] / 2
    centered_points = image_points.copy()
    centered_points[:, 0] -= image_center_x
    return centered_points


def reproject_to_3d(image_points, frame_shape, Z=0, Y_flip = Y_FLIP, X_flip = X_FLIP):
    """
    Reproject 2D points to 3D assuming they lie on a plane at Z=0

    :param image_points: Nx2 array of 2D image points (centered)
    :param frame_shape: Shape of the image frame (height, width)
    :param Z: Z-coordinate of the plane (default is 0)
    :return: Nx3 array of 3D points
    """
    # Ensure image_points is a numpy array
    image_points = np.array(image_points, dtype=np.float32)

    # Get rotation and translation vectors
    rvec, tvec = rvecs[0], tvecs[0]

    # Convert rotation vector to rotation matrix
    R, _ = cv2.Rodrigues(rvec)

    # Invert [R|t]
    Rt = np.column_stack((R, tvec))
    P = mtx.dot(Rt)
    P_inv = np.linalg.pinv(P)

    # Add homogeneous coordinate to image points
    points_homogeneous = np.column_stack((image_points, np.ones(len(image_points))))

    # Reproject to 3D
    points_3d_homogeneous = P_inv.dot(points_homogeneous.T).T

    # Convert from homogeneous coordinates to 3D coordinates
    points_3d = points_3d_homogeneous[:, :3] / points_3d_homogeneous[:, 3:]

    # Adjust Z coordinate
    points_3d[:, 2] = Z

    # Flip Y coordinate if needed
    if Y_flip:
        points_3d[:, 1] *= -1
    if X_flip:
        points_3d[:, 0] *= -1
    return points_3d


if len(tennis_ball_centers) == 0:
    print("No tennis balls detected. Skipping 3D reprojection...")
    exit()

# Original image points
original_image_points = np.array([[x, y]], dtype=np.float32)

# Center the image coordinates
centered_image_points = center_image_coordinates(original_image_points, frame.shape)

# Reproject to 3D
print(frame.shape)
points_3d = reproject_to_3d(centered_image_points, frame.shape)

# Visualize the results
fig = plt.figure(figsize=(20, 6))

# Original image
ax_img = fig.add_subplot(131)
ax_img.imshow(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))
ax_img.set_title(IMAGE_PATH)
ax_img.axis('off')

# 2D plot
ax1 = fig.add_subplot(132)
scatter = ax1.scatter(original_image_points[:, 0], original_image_points[:, 1], c='r', s=50)
ax1.set_xlim(0, frame.shape[1])
ax1.set_ylim(frame.shape[0], 0)
ax1.set_xlabel('X')
ax1.set_ylabel('Y')
ax1.set_title('Original 2D Image Points')
ax1.invert_yaxis()

# Add vertical line at image center
ax1.axvline(x=frame.shape[1] / 2, color='r', linestyle='--', alpha=0.5)

# Add legend for 2D plot
for i, (x, y) in enumerate(original_image_points):
    ax1.annotate(f'({x:.1f}, {y:.1f})', (x, y), xytext=(5, 5), textcoords='offset points')

# 3D plot
ax2 = fig.add_subplot(133, projection='3d')
scatter3d = ax2.scatter(points_3d[:, 0], points_3d[:, 1], points_3d[:, 2])
# Modify axis limits for X and Y
max_range = np.max([np.abs(points_3d[:, 0]).max(), np.abs(points_3d[:, 1]).max()])
ax2.set_xlim(-max_range, max_range)
ax2.set_ylim(-max_range, max_range)
ax2.set_xlabel('X')
ax2.set_ylabel('Y')
ax2.set_zlabel('Z')
ax2.set_title('Reprojected 3D Points (X=0 at image center)')

# Add horizontal plane at Z=0
xx, yy = np.meshgrid(np.linspace(-max_range, max_range, 2), np.linspace(-max_range, max_range, 2))
zz = np.zeros_like(xx)
ax2.plot_surface(xx, yy, zz, alpha=0.2, color='gray')

# Add legend for 3D plot
for i, (x, y, z) in enumerate(points_3d):
    ax2.text(x, y, z, f'({x:.2f}, {y:.2f}, {z:.2f})', fontsize=9)

# Add a vertical line at X=0 in the 3D plot
ax2.plot([0, 0], [ax2.get_ylim()[0], ax2.get_ylim()[1]], [0, 0], 'r--', alpha=0.5)

plt.tight_layout()
plt.show()

# Print the 3D coordinates
print("Reprojected 3D coordinates:")
print(points_3d)